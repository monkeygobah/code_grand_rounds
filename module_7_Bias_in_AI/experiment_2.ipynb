{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obermeyer et. al. 2019- Examining the mechanism of bias**\n",
    "\n",
    "\n",
    "### Becuase the authors are simulating the exact algorithm used nation wide, they were able to evaluate at the inputs and outputs to the model in order to probe the mechanism of the bias The algorithm took as input various insurance claims data, including age, sex, types of insurance, medication information, and more. Notably, however, the inputs excluded race (in an effort to be unbiased).\n",
    "\n",
    "### In return, the algorithm predicted a patient's health needs, which, in essence, boiled down to predicting the cost of healthcare for any individual. When the predicted costs from the algorithm were plotted against actual costs, it was clear that black and white patints have the same costs at all risk scores predicted by the algorithm. This allowed them to say that the predicted costs of the algorithm are well calibrated, meaning the algorithm is good at predicting the cost of both black and white paetients based on the predicted risk score.\n",
    "\n",
    "### If your eyebrows are going up at this point, that is good, because the authors' were as well. The authors knew from their earlier experiments that Black patients were generally sicker than White patients at identical predicted risk levels. It also follows reason that sicker patients normally need and receive more care, so we would expect to see this represented in the cost of healthcare for black and white patients (i,e., the cost of healthcare for black patients should be predicted as higher given worse health at the same predicted risk level as White patients). But why didn't this reflect in the algorithm's prediction? It became evident that there was a disconnect between a patient's need for healthcare and the healthcare they received, and there must be a wedge that has crept in between needing and receiving healthcare. This wedge is the race of the patient. When they measure health based on number of chronic illnesses in a different analysis, they found that black patients generate lower costs than white patients at the same number of chronic illnesses. \n",
    "\n",
    "### So while the algorithm was very good at making predictions on the cost of patients (as it was designed to do), the implication of this is that it said that sicker Black patients incur the same cost of healthcare, which will mean that sicker black patients receive less attention from the healthcare system (as again, the algorithm was functioning based on predicted healthcare costs). This all boiled down to one main reason, and that is the assumption that patients with similar costs of healthcare have similar health needs is fundamentally incorrect. \n",
    "\n",
    "### Due to systemic disparities (geography and differential access to transportation, competing demands from jobs or child care, knowledge of reasons to seek care, etc.) as well as disparities directly related to race (direct (“taste-based”) discrimination, changes to the doctor–patient relationship, etc), there are substantially more barriers to black patient's interacting with the health care system which, in and of itself, leads to reduced use of healthcare (i.e., lower cost). There is, in fact, a wide berth of literature that reports on the effects of poverty and access to healthcare as well as the effects of race within the healthcarfe system (ref ref ref ref ref). Even though the initial algorithm did not contain race as an input, the algorithm still perpetuated systemic disparities throughout the system because of what it was directly evaluating (costs) without consideration of external factors.\n",
    "\n",
    "### This leads to a conclusion which is that he label an algorithm is trained on can significantly influence its outcomes. In their study, the algorithm's focus on predicting future costs seemed logical at first. If a program's goal is to reduce costs, it seems reasonable to target patients who might incur the highest future costs. This label choice is in fact commonly used by many ranging from academic institutions, non-profit hospitals, and governmental agencies.\n",
    "\n",
    "### However, choosing future costs as the sole label isn't the only or perhaps the optimal choice. Care management programs, for instance, don't primarily aim to cut costs across the board. Their primary objective is preventing severe health issues that might lead to emergency healthcare interventions. In fact, these programs can increase certain types of costs, like primary care or home health support. Therefore, labels predicting avoidable future costs tied to emergency treatments or hospitalizations might be more reflective of real-world needs. Alternatively, instead of focusing on costs, algorithms could predict health metrics, such as the number of active chronic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of : Dissecting racial bias in an algorithm used to manage the health of populations\n",
    "# and implications: https://www.science.org/doi/full/10.1126/science.aax2342\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Racial bias in health algorithms\n",
    "The U.S. health care system uses commercial algorithms to guide health decisions. Obermeyer et al. find evidence of racial bias in one widely used algorithm, such that Black patients assigned the same level of risk by the algorithm are sicker than White patients (see the Perspective by Benjamin). The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half. Bias occurs because the algorithm uses health costs as a proxy for health needs. Less money is spent on Black patients who have the same level of need, and the algorithm thus falsely concludes that Black patients are healthier than equally sick White patients. Reformulating the algorithm so that it no longer uses costs as a proxy for needs eliminates the racial bias in predicting who needs extra care."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background \n",
    "### Study analyzed a type of algoriothm applied ti ~200 million people (they modeled the algorithm applied at this scale)\n",
    "### Algorithm goal is to stratify people by risk factor and identify high risk people to provide additional resources\n",
    "\n",
    "## Experiement 1- Health Disparities based on Risk Score\n",
    "### Patients binned by race via hospital reporting (6079 black, 43539 white), --> 11,929 and 88,080 patient-years, respectively (1 patient-year represents data collected for an individual patient in a calendar year) \n",
    "### Calculated risk scores using algorithm > 55th percentile --> primary care refferral, > 97th percentile --> auto enrollment in program\n",
    "### Initially calculate overall view of patients health (measures health status, chronic conditions) by race --> show that black individuals have hgiher illness burden\n",
    "### At the high risk threshold (97% risk score), black individuals have 26.3 % more chronic conditions (p<=.001)\n",
    "### Means that for black people categorized at the same level of risk, there is significantly more illness burden in these patients compared to white people\n",
    "### Immediate disparity in referral for screening as less healthy black people score at simialr risk score to more healthy white people\n",
    "### Quantify this finding by simulating world with no gap in health conditional on risk --> essentially remmoved the difference in the risk score between white and black patients\n",
    "    #### When going through the algorithm, they said that if there was a white patient who was above the threshold line with less chronic conditions than a black patient below the threshold line, they replaced the white patient with the black patient. Continue this process until both black and white patients on either side of the threshold have similar health conditinos\n",
    "### Rerun the simulation using the original algorithm with patient population corrected based on this above process, showed that the percentage of black patients auto enrolled in the program (above the 97th percentile)increased from 17.7 in the orignial experiment to 46.5%\n",
    "### Result is that the original algoroithm was clearly not calculating the risk assessment for black people in need of referral, as black individuals with more chronic health conditinos (in the original algorithm) were being placed at the same risk threshold as healthier white patients\n",
    "### They then showed that this same discrepancy exists for biomarkers such as HTN, HbA1C, LDL, anemia and renal failure (meaning that black patients had worse numbers (less healthy) for these biomarkers than white patients at the same calculated risk score)\n",
    "\n",
    "## Experiment 2- Examining the mechanism of bias\n",
    "\n",
    "\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

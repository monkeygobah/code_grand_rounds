{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473a0be",
   "metadata": {},
   "source": [
    "# Coding Applications in Medicine: Data Science - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1e953",
   "metadata": {},
   "source": [
    "Module adapted from Kaggle: https://www.kaggle.com/code/mariapushkareva/medical-insurance-cost-with-linear-regression/notebook\n",
    "\n",
    "Dataset source: https://github.com/stedy/Machine-Learning-with-R-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227153a6",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e732759e",
   "metadata": {},
   "source": [
    "Data Science is a multidisciplinary field that integrates computation, math/statistics, and domain knowledge to understand the world and solve problems. \n",
    "\n",
    "The data science lifecycle consists of:\n",
    "1. Question/problem formulation\n",
    "2. Data acquisition and cleaning\n",
    "3. Exploratory data analysis and visualization\n",
    "4. Prediction and inference\n",
    "\n",
    "In this notebook, we will explore a sample data on medical insurance and practice handling data using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362574e8",
   "metadata": {},
   "source": [
    "## Pandas Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da228a",
   "metadata": {},
   "source": [
    "After obtaining the data, the first step is to read the data into the Python notebook. We will use the Pandas data structure to store our data and use it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a Pandas data frame.\n",
    "insuranceDF= pd.read_csv(\"data/insurance_modified.csv\")\n",
    "\n",
    "# Preview the dataframe by calling the variable (useful to double-checking your work).\n",
    "# Note: Missing data is normally shown as NaN (similar to null).\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The index can be non-numerical and non-unique.\n",
    "\n",
    "# Set the \"sex\" column to be the index of the dataframe.\n",
    "insuranceDF.set_index(\"sex\", inplace=True)\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our usecase, we would like to keep the default index setting.\n",
    "\n",
    "insuranceDF.reset_index(inplace=True)\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc to select rows/columns by label name.\n",
    "\n",
    "# View the information for person number 5 to 10 (inclusive).\n",
    "insuranceDF.loc[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View only the demographic information for person number 5 to 10 (inclusive).\n",
    "insuranceDF.loc[5:10, \"sex\":\"region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View only the sex, bmi, and smoker information for everyone.\n",
    "insuranceDF.loc[:, [\"sex\", \"bmi\", \"smoker\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas can also use iloc to select rows/columns by number.\n",
    "# Note: Counting start with 0 and the end is not inclusive.\n",
    "\n",
    "# View only the sex, bmi, and smoker information for the 5th to 10th person (inclusive).\n",
    "insuranceDF.iloc[4:10, [0, 2, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check everyone to see if they are a smoker.\n",
    "\n",
    "# Note: The [] operator is the same as the loc operator.\n",
    "insuranceDF[\"smoker\"] == \"yes\" \n",
    "\n",
    "# This is the same as \n",
    "### insuranceDF.loc[:, \"smoker\"] == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0df5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out our existing dataframe to include only the first 10 smokers on the list.\n",
    "insuranceDF.loc[insuranceDF[\"smoker\"] == \"yes\"].head(10)\n",
    "\n",
    "# This is the same as\n",
    "### insuranceDF.loc[insuranceDF[\"smoker\"] == \"yes\"].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b99821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values will either be treated as 0 or will be skipped in certain calculations.\n",
    "\n",
    "# Statistics that is reported by default for dataframes.\n",
    "insuranceDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics that is reported by default for series (numerical).\n",
    "insuranceDF[\"bmi\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics that is reported by default for series (non-numerical).\n",
    "insuranceDF[\"smoker\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the demographics of the 10 people with the lowest insurance charges.\n",
    "insuranceDF.sort_values(\"charges\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group all the people by region, aggregate by median value.\n",
    "insuranceDF.groupby(\"region\").agg('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only regions where the mean BMI is greater than 30.\n",
    "\n",
    "def isHighMeanBMI(df):\n",
    "    return df[\"bmi\"].mean() > 30\n",
    "\n",
    "insuranceDF.groupby(\"region\").filter(isHighMeanBMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49090815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NaN values we have for each column.\n",
    "insuranceDF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the children column.\n",
    "insuranceDF[\"children\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to handle missing data is to remove rows where there are NaN values.\n",
    "\n",
    "# Drops rows where NaN values exists.\n",
    "insuranceDF.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to handle missing data is to remove columns where there are NaN values.\n",
    "\n",
    "# Drops columns where NaN values exists\n",
    "insuranceDF.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to handle missing data is to replace the NaN values with a reasonable value.\n",
    "\n",
    "# Replace the NaN values in \"children\" column with 0.\n",
    "insuranceDF[\"children\"].fillna(0)\n",
    "\n",
    "# This is the same as \n",
    "### insuranceDF[\"children\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column named \"parent\" that determines whether a given person is a parent\n",
    "#  given the number of children they have.\n",
    "\n",
    "def isParent(children):\n",
    "    if children > 0:\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "insuranceDF[\"parent\"] = insuranceDF[\"children\"].apply(isParent)\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the newly created \"parent\" column.\n",
    "insuranceDF = insuranceDF.drop(\"parent\", axis=\"columns\")\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757223af",
   "metadata": {},
   "source": [
    "## Text Wrangling and Regex Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c7576",
   "metadata": {},
   "source": [
    "As you may have already noticed, there are many different forms of data, including numerical, boolean (true or false), text, etc. In general, textual data may need to be manipulated and/or clean-up in order to be useful in later analysis.\n",
    "\n",
    "The following section will show ways to manipulate strings (textual data) on Pandas series. This can be applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37684bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the text for the \"region\" column to be upper case and append the word \"region\" at the end.\n",
    "insuranceDF[\"region\"] = insuranceDF[\"region\"].str.upper() + \" region\"\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the space character with the hyphen character for the \"region\" column.\n",
    "insuranceDF[\"region\"] = insuranceDF[\"region\"].str.replace(' ', '-')\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5173551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"region\" column by the hypen character and take only the first element of the result.\n",
    "insuranceDF[\"region\"] = insuranceDF[\"region\"].str.split('-').str[0]\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b36afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first character from the \"sex\" column to convert it to upper case.\n",
    "insuranceDF[\"sex\"] = insuranceDF[\"sex\"].str[0:1].str.upper()\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb556f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the region is in the north.\n",
    "insuranceDF[\"In North Region\"] = insuranceDF[\"region\"].str.contains(\"NORTH\")\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeabb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of the string of the \"smoker\" column.\n",
    "insuranceDF[\"smoker.len\"] = insuranceDF[\"smoker\"].str.len()\n",
    "insuranceDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0080fb",
   "metadata": {},
   "source": [
    "Regex (regular expression) describes a sequence of characters that specifies a search pattern. Regex is a powerful way to search of specific patterns within text when done correctly, but can be quite complex/confusing. \n",
    "\n",
    "\n",
    "For more information: https://docs.python.org/3/howto/regex.html\n",
    "\n",
    "Website to check/test your regex expression: https://regex101.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aa0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern: \n",
    "# - First character is 'S'.\n",
    "# - Followed by any characters exactly two times.\n",
    "# - Followed by any character that is not 'a' to 'z' at least once.\n",
    "# - Followed by any word character zero times or more.\n",
    "# - Followed by 'T'.\n",
    "pattern = r\"S.{2}[^a-z]+\\w*T\"\n",
    "\n",
    "# Find all matches to the above pattern within the 'region' column.\n",
    "insuranceDF[\"region\"].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abed9fd",
   "metadata": {},
   "source": [
    "We have shown some of the most commonly used pandas operations/functions, but we have barely scratched the surface! To learn more about all the other existing pandas functions and more information, check the following:\n",
    "- User Guide (Pandas): https://pandas.pydata.org/docs/user_guide/index.html#\n",
    "- API Reference (Pandas): https://pandas.pydata.org/docs/reference/index.html\n",
    "\n",
    "Other helpful guides and references to get you started:\n",
    "- User Guide (Python): https://docs.python.org/3/tutorial/\n",
    "- Library Reference (Python): https://docs.python.org/3/library/index.html\n",
    "- Language Reference (Python): https://docs.python.org/3/reference/index.html\n",
    "- User Guide (Numpy): https://numpy.org/doc/stable/user/index.html#\n",
    "- API Reference (Numpy): https://numpy.org/doc/stable/reference/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0609b3b",
   "metadata": {},
   "source": [
    "## Practice: Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151bfe1",
   "metadata": {},
   "source": [
    "Find the average insurance cost for overweight individuals living in the northeast region. We have provided a guide to follow through to solve this problem. Note that there can be multiple approaches to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data for reset convenience.\n",
    "insuranceDF = pd.read_csv(\"data/insurance.csv\")\n",
    "\n",
    "# Provided BMI category table.\n",
    "bmiCategoriesDF = pd.read_csv(\"data/bmiCategories.csv\")\n",
    "\n",
    "# Step 0: Check the data you are working with and think about what manipulations are needed.\n",
    "\n",
    "# Step 1: Modify the BMI category table to include the min and max BMI for each category.\n",
    "# Step 1a: Obtain the min and max BMI from the BMI column.\n",
    "\n",
    "### bmiCategoriesDF[\"min bmi\"] = ________\n",
    "### bmiCategoriesDF[\"max bmi\"] = ________\n",
    "\n",
    "# Step 1b: Reassign the non-numerical BMI values to reasonable numbers. We will use the at function.\n",
    "# Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n",
    "\n",
    "### bmiCategoriesDF.at[________, ________] = ________\n",
    "### bmiCategoriesDF.at[________, ________] = ________\n",
    "\n",
    "# Step 1c: Convert the min and max bmi column to be float data type.\n",
    "\n",
    "### bmiCategoriesDF[________] = bmiCategoriesDF[________].astype(float)\n",
    "### bmiCategoriesDF[________] = bmiCategoriesDF[________].astype(float)\n",
    "\n",
    "# Step 2: Combine the two data frames. In this example, we will use the merge function.\n",
    "# Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "### mergedDF = ________.merge(________, how=\"cross\")\n",
    "\n",
    "# Step 3: Filter out the data frame to retain only rows where the BMI matches the BMI category.\n",
    "\n",
    "### mergedDF = mergedDF[(________) & (________)]\n",
    "### mergedDF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Step 4: Group mergedDF by region and the BMI weight status and aggregate the result by the mean.\n",
    "\n",
    "### mergedMeanDF = mergedDF.________.________.reset_index()\n",
    "\n",
    "# Step 5: Filter the mergedMeanDF by the region and BMI weight status.\n",
    "\n",
    "### resultDF = ________\n",
    "\n",
    "# Step 6: Select only the relevant data.\n",
    "\n",
    "### result = (________, ________, ________)\n",
    "\n",
    "### print(\"The average insurance charge for an {0} person living in the {1} region is ${2}.\"\n",
    "###       .format(result[0], result[1], result[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dd58a",
   "metadata": {},
   "source": [
    "Below is one way to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68233ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8348ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data for reset convenience.\n",
    "insuranceDF = pd.read_csv(\"data/insurance.csv\")\n",
    "bmiCategoriesDF = pd.read_csv(\"data/bmiCategories.csv\")\n",
    "\n",
    "# Modify the BMI category table to include the min and max BMI for each category.\n",
    "# Example using regex.\n",
    "### bmiCategoriesDF[\"min bmi\"] = bmiCategoriesDF[\"BMI\"].str.split(r\"\\s(?:-|and)*\\s*\").str[0]\n",
    "### bmiCategoriesDF[\"max bmi\"] = bmiCategoriesDF[\"BMI\"].str.split(r\"\\s(?:-|and)*\\s*\").str[1]\n",
    " \n",
    "# Example without using regex.\n",
    "bmiCategoriesDF[\"min bmi\"] = bmiCategoriesDF[\"BMI\"].str.split().str[0]\n",
    "bmiCategoriesDF[\"max bmi\"] = bmiCategoriesDF[\"BMI\"].str.split().str[-1]\n",
    "\n",
    "# Reassign the non-numerical BMI values to reasonable numbers.\n",
    "bmiCategoriesDF.at[0, \"min bmi\"] = 0\n",
    "bmiCategoriesDF.at[3, \"max bmi\"] = 100\n",
    "\n",
    "# Convert the min and max bmi column to be float data type.\n",
    "bmiCategoriesDF[\"min bmi\"] = bmiCategoriesDF[\"min bmi\"].astype(float)\n",
    "bmiCategoriesDF[\"max bmi\"] = bmiCategoriesDF[\"max bmi\"].astype(float)\n",
    "\n",
    "# Combine the two data frames.\n",
    "#insuranceDF = insuranceDF.merge(bmiCategoriesDF, how=\"cross\")\n",
    "mergedDF = insuranceDF.merge(bmiCategoriesDF, how=\"cross\")\n",
    "\n",
    "# Filter out the data frame to retain only rows where the BMI matches the BMI category.\n",
    "mergedDF = mergedDF[(mergedDF[\"bmi\"] >= mergedDF[\"min bmi\"]) \n",
    "                          & (mergedDF[\"bmi\"] < mergedDF[\"max bmi\"])]\n",
    "mergedDF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Group insuranceDF by region and the BMI weight status and aggregate the result by the mean.\n",
    "mergedMeanDF = mergedDF.groupby([\"region\", \"Weight Status\"]).agg(\"mean\").reset_index()\n",
    "\n",
    "# Filter the insuranceDF by the region and BMI weight status.\n",
    "resultDF = mergedMeanDF[(mergedMeanDF[\"region\"] == \"northeast\") \n",
    "                          & (mergedMeanDF[\"Weight Status\"] == \"Overweight\")].reset_index()\n",
    "\n",
    "# Select only the relevant data.\n",
    "resultFromDF = (resultDF[\"Weight Status\"][0].lower(), \n",
    "                resultDF[\"region\"][0], \n",
    "                str(round(resultDF[\"charges\"][0], 2)))\n",
    "\n",
    "print(\"The average insurance charge for an {0} person living in the {1} region is ${2}.\"\n",
    "      .format(resultFromDF[0], resultFromDF[1], resultFromDF[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd51125",
   "metadata": {},
   "source": [
    "### Other Considerations 1: Data cleaning/handling outside of Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a0bc2a",
   "metadata": {},
   "source": [
    "In this notebook, we are directly modifying the data after directly reading the data file into Pandas dataframe. There may be instances where you might not be using the Pandas library for the data analysis. In those situations, the data cleaning and processing steps will need to be done via scripts.\n",
    "\n",
    "The general approach would be to:\n",
    "1. Read the file and store the corresponding data in data structures\n",
    "2. Modify the data with user-defined functions\n",
    "3. Write the data into a new file\n",
    "\n",
    "References:\n",
    "- Python3 I/O tutorial: https://docs.python.org/3/tutorial/inputoutput.html\n",
    "- Python3 CSV I/O tutorial: https://docs.python.org/3/library/csv.html\n",
    "\n",
    "The following code blocks will mimic the same code we have written above used to modify the bmiCategories table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined function to modify the bmi value. \n",
    "# Category: String with the bmi categorization data.\n",
    "# Index: 0 for Min and -1 for Max.\n",
    "def modifyBmi(category, index):\n",
    "    # Split the bmi category text by ' ' and take the element at the index position of the resulting list.\n",
    "    bmi = category.split()[index]\n",
    "    # Check to see if the extracted text is a float (replace only one instance of '.' and check if it is a digit).\n",
    "    if category.split()[index].replace('.', '', 1).isdigit():\n",
    "        return float(bmi)\n",
    "    # Replacement for non-numerical min bmi.\n",
    "    if index == 0:\n",
    "        return 0.0\n",
    "    # Replacement for non-numerical max bmi.\n",
    "    return 100.0\n",
    "\n",
    "# Open the file with bmi categories data in read-only format.\n",
    "with open('data/bmiCategories.csv', 'r') as f:\n",
    "    # Create a dictionary based on data in the file.\n",
    "    dr = csv.DictReader(f)\n",
    "    # Create a list of tuples that contains data obtained from the dictionary.\n",
    "    # Here we are also introducing the max and min bmi using our previously defined function.\n",
    "    rowList = [(row[\"BMI\"], row[\"Weight Status\"], modifyBmi(row[\"BMI\"], 0), \n",
    "                modifyBmi(row[\"BMI\"], -1)) for row in dr]\n",
    "    # List of field names used for the header line of the csv we will write later.\n",
    "    fieldnameList = dr.fieldnames + [\"Min BMI\", \"Max BMI\"]\n",
    "\n",
    "# Open the file with bmi categories data in write format.\n",
    "# This will create an empty new file.\n",
    "with open('data/modifiedBmiCategories.csv', 'w', newline='') as f:\n",
    "    # Writes in csv format (comma as delimiter).\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    # Writes field names as the first row.\n",
    "    writer.writerow(fieldnameList)\n",
    "    # Writes the list of data in row format (new line for each row).\n",
    "    for row in rowList:\n",
    "        writer.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bee43",
   "metadata": {},
   "source": [
    "### Other Considerations 2: Working with databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e0bc8",
   "metadata": {},
   "source": [
    "In this notebook, we are obtaining the data directly from a file. There may be instances where the data is stored in a database, and you need to export part of the data from the database. One of the most popular languages to handle databases is SQL. In general, if you also need to manipulate the queried data, it is better to do so with scripts after querying and exporting rather than through SQL/within database queries.\n",
    "\n",
    "References:\n",
    "- SQLite Documentation: https://www.sqlite.org/docs.html\n",
    "- Python3 SQLite Tutorial: https://docs.python.org/3/library/sqlite3.html\n",
    "\n",
    "The following code blocks will mimic the same code we have written above after modifying the bmiCategories table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishes a connection to the local database file.\n",
    "# Normally, you would establish a connection to a remote database.\n",
    "con = sqlite3.connect(\"data/insurance.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# Checks to see if \"insurance\" table already exists in the database. \n",
    "# If it already exists, then we will clear the data from the table (mainly used for reset convenience).\n",
    "if cur.execute(\"SELECT COUNT(*) FROM sqlite_master \" +\n",
    "               \"WHERE type = 'table' AND name = 'insurance'\").fetchone()[0] > 0:\n",
    "    cur.execute(\"DELETE FROM insurance\")\n",
    "    con.commit()\n",
    "\n",
    "    # This will remove the table instead.\n",
    "    ###cur.execute(\"DROP TABLE insurance\")\n",
    "    ###con.commit()\n",
    "\n",
    "# Creates the \"insurance\" table (if it does not exist) based on the provided schema.\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS \" + \n",
    "                \"insurance (age NUMBER(3), sex VARCHAR2(10), bmi NUMBER(6, 3), children NUMBER(2), \" + \n",
    "                           \"smoker VARCHAR2(3), region VARCHAR2(9), charges NUMBER(11, 5));\")\n",
    "\n",
    "# Open the file with the insurance data in a read-only format.\n",
    "with open(\"data/insurance.csv\", 'r') as f:\n",
    "    # Create a dictionary based on data in the file.\n",
    "    dr = csv.DictReader(f)\n",
    "    # Create a list of tuples that contains data obtained from the dictionary.\n",
    "    rowList = [(row[\"age\"], row[\"sex\"], row[\"bmi\"], row[\"children\"],\n",
    "                row[\"smoker\"], row[\"region\"], row[\"charges\"]) for row in dr]\n",
    "\n",
    "# Bulk insert operation into the \"insurance\" table.\n",
    "cur.executemany(\"INSERT INTO insurance (age, sex, bmi, children, smoker, region, charges) \" +\n",
    "                    \"VALUES (?, ?, ?, ?, ?, ?, ?);\", rowList)\n",
    "con.commit()\n",
    "\n",
    "# Checks to see if \"bmicategories\" table already exists in the database. \n",
    "# If it already exists, then we will clear the data from the table (mainly used for reset convenience).\n",
    "if cur.execute(\"SELECT COUNT(*) FROM sqlite_master \" + \n",
    "               \"WHERE type = 'table' AND name = 'bmicategories'\").fetchone()[0] > 0:\n",
    "    cur.execute(\"DELETE FROM bmicategories\")\n",
    "    con.commit()\n",
    "\n",
    "    # This will remove the table instead.\n",
    "    #cur.execute(\"DROP TABLE bmicategories\")\n",
    "    #con.commit()\n",
    "\n",
    "# Creates the \"insurance\" table (if it does not exist) based on the provided schema.\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS \" +\n",
    "                \"bmicategories (BMI VARCHAR2(15), 'Weight Status' VARCHAR2(15), \"\n",
    "                               \"'Min BMI' NUMBER(6, 3), 'Max BMI' NUMBER(4, 1));\")\n",
    "\n",
    "# Open the file with the insurance data in a read-only format.\n",
    "with open(\"data/modifiedBmiCategories.csv\", 'r') as f:\n",
    "    # Create a dictionary based on data in the file.\n",
    "    dr = csv.DictReader(f)\n",
    "    # Create a list of tuples that contains data obtained from the dictionary.\n",
    "    rowList = [(row[\"BMI\"], row[\"Weight Status\"], row[\"Min BMI\"], row[\"Max BMI\"]) for row in dr]\n",
    "\n",
    "# Bulk insert operation into the \"bmicategories\" table.\n",
    "cur.executemany(\"INSERT INTO bmicategories (BMI, 'Weight Status', 'Min BMI', 'Max BMI') \" +\n",
    "                    \"VALUES (?, ?, ?, ?);\", rowList)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ccd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query statement to obtain data. Generally SQL query statement are readable.\n",
    "query = (\"SELECT bmicategories.'Weight Status', insurance.region, AVG(insurance.charges) \" + \n",
    "         \"FROM insurance FULL OUTER JOIN bmicategories \" +\n",
    "         \"WHERE insurance.bmi >= bmicategories.'Min BMI' \" +\n",
    "         \"AND insurance.bmi < bmicategories.'Max BMI' \" +\n",
    "         \"GROUP BY insurance.region, bmicategories.'Weight Status' \" +\n",
    "         \"HAVING insurance.region = 'northeast' \" +\n",
    "         \"AND bmicategories.'Weight Status' = 'Overweight';\")\n",
    "\n",
    "# Execute the query statement and fetch the next row (in this case, the first and only row).\n",
    "res = cur.execute(query).fetchone()\n",
    "\n",
    "# Select only the relevant data.\n",
    "resultFromSQL = (res[0].lower(), \n",
    "                 res[1], \n",
    "                 str(round(res[2], 2)))\n",
    "\n",
    "print(\"The average insurance charge for an {0} person living in the {1} region is ${2}.\"\n",
    "      .format(resultFromSQL[0], resultFromSQL[1], resultFromSQL[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bac0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection.\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b3471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
